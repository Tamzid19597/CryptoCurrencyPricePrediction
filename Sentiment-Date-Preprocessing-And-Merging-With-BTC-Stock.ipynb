{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+XndSx+NND+VaFXhhWJD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tamzid19597/CryptoCurrencyPricePrediction/blob/main/Sentiment-Date-Preprocessing-And-Merging-With-BTC-Stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "nDnofMopMqlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umfzOwimMeaV",
        "outputId": "c6e3732a-39de-4516-deb8-bf038da0c9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 45.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=39b839ca0bc74ec6a58c2ec4b7c6e7ed1470d6ec2315267f98a641dbc29d25f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tweet-preprocessor\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install keras\n",
        "!pip install tweet-preprocessor\n",
        "!pip install vaderSentiment\n",
        "import pyspark as spark\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.functions import col,udf,monotonically_increasing_id,unix_timestamp,round,avg\n",
        "import re\n",
        "sc = spark.SparkContext()\n",
        "sql = spark.SQLContext(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tweet Dataset"
      ],
      "metadata": {
        "id": "1zBK8JvNPUF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import functions as sf\n",
        "TwDF=pd.read_csv('sentiment_preprocessed.csv',error_bad_lines=False,engine = 'python',header = None)\n",
        "TwDF = TwDF.drop([0], axis=1)\n",
        "FullDataTw=sql.createDataFrame(TwDF)\n",
        "FullDataTw = FullDataTw.dropna()\n",
        "FullDataTw.select(monotonically_increasing_id().alias(\"rowId\"),\"*\")\n",
        "FullDataTw = FullDataTw.withColumnRenamed('1', 'DateTime')\n",
        "FullDataTw = FullDataTw.withColumnRenamed('2', 'Date')\n",
        "FullDataTw=FullDataTw.withColumn('Date', regexp_replace('Date', '/', '-'))\n",
        "FullDataTw = FullDataTw.withColumnRenamed('3', 'Time') #setting column names of Twitter dataset\n",
        "FullDataTw = FullDataTw.withColumnRenamed('4', 'Tweet')\n",
        "FullDataTw =FullDataTw.withColumn('DateTime', sf.concat(sf.col('Date'),sf.lit(' '),sf.col('Time')))\n",
        "FullDataTw=FullDataTw.filter(FullDataTw.Date!='1')\n",
        "FullDataTw=FullDataTw.drop(\"Time\")\n",
        "Tw_samp = FullDataTw\n",
        "Tw_samp.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9YyTPA8PWgb",
        "outputId": "4acd8c5f-e783-44da-ff6f-f1d707c14170"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------------------+\n",
            "|           DateTime|      Date|               Tweet|\n",
            "+-------------------+----------+--------------------+\n",
            "|2022-01-31 23:59:57|2022-01-31|#Bitcoin  is one ...|\n",
            "|2022-01-31 23:59:52|2022-01-31|Lol... Oh, you ju...|\n",
            "|2022-01-31 23:59:46|2022-01-31|One of the larges...|\n",
            "|2022-01-31 23:59:33|2022-01-31|However, if the r...|\n",
            "|2022-01-31 23:59:33|2022-01-31|The CoinShares re...|\n",
            "+-------------------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing Twitter dataframe"
      ],
      "metadata": {
        "id": "qq1qT7R0R_U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import preprocessor as p #cleaning each tweet using tweet-preprocessor like removing hashtags,urls,emojis....\n",
        "def function_udf(input_str):\n",
        "    input_str = re.sub(r'RT', '', input_str)\n",
        "    p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION)\n",
        "    input_str = p.clean(input_str)\n",
        "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", input_str).split())\n",
        "func_udf = udf(function_udf, StringType())\n",
        "CleanDF = Tw_samp.withColumn('CleanedTweets', func_udf(Tw_samp['Tweet']))\n",
        "CleanDF.show(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe5S5UQnR_nf",
        "outputId": "28464f35-ae07-477d-985e-e5f838ef4a7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------------------+--------------------+\n",
            "|           DateTime|      Date|               Tweet|       CleanedTweets|\n",
            "+-------------------+----------+--------------------+--------------------+\n",
            "|2022-01-31 23:59:57|2022-01-31|#Bitcoin  is one ...|Bitcoin is one of...|\n",
            "|2022-01-31 23:59:52|2022-01-31|Lol... Oh, you ju...|Lol Oh you just r...|\n",
            "|2022-01-31 23:59:46|2022-01-31|One of the larges...|One of the larges...|\n",
            "+-------------------+----------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis using Vader packages"
      ],
      "metadata": {
        "id": "bEjpCZvhVIun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "def senti_score_udf(sentence):\n",
        "    snt = analyser.polarity_scores(sentence)\n",
        "    return ([snt['neg'], snt['neu'], snt['pos'], snt['compound']])\n",
        "func_udf2 = udf(senti_score_udf, ArrayType(FloatType()))\n",
        "CleanDF = CleanDF.withColumn('p_neg', func_udf2(CleanDF['CleanedTweets'])[0])\n",
        "CleanDF = CleanDF.withColumn('p_neu', func_udf2(CleanDF['CleanedTweets'])[1])\n",
        "CleanDF = CleanDF.withColumn('p_pos', func_udf2(CleanDF['CleanedTweets'])[2])\n",
        "CleanDF = CleanDF.withColumn('p_comp', func_udf2(CleanDF['CleanedTweets'])[3])\n",
        "CleanDF = CleanDF.withColumn(\"DateTime\",CleanDF['DateTime'].cast(TimestampType()))\n",
        "CleanDF.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxy9z-xDVQrr",
        "outputId": "f1941202-f34a-444f-a281-d4e1b970477d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------------------+--------------------+-----+-----+-----+-------+\n",
            "|           DateTime|      Date|               Tweet|       CleanedTweets|p_neg|p_neu|p_pos| p_comp|\n",
            "+-------------------+----------+--------------------+--------------------+-----+-----+-----+-------+\n",
            "|2022-01-31 23:59:57|2022-01-31|#Bitcoin  is one ...|Bitcoin is one of...|  0.0|0.809|0.191| 0.8555|\n",
            "|2022-01-31 23:59:52|2022-01-31|Lol... Oh, you ju...|Lol Oh you just r...|  0.0|0.608|0.392| 0.7003|\n",
            "|2022-01-31 23:59:46|2022-01-31|One of the larges...|One of the larges...|0.244|0.659|0.097|-0.5859|\n",
            "+-------------------+----------+--------------------+--------------------+-----+-----+-----+-------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting necessary columns"
      ],
      "metadata": {
        "id": "PaktC3gDvs8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FinalTw = CleanDF.selectExpr(\"DateTime as Date_Time\",\"Date as Date\", \"CleanedTweets as Cleaned_Tweets\", \"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "FinalTw.show(5) #selecting necessary columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gNf11rvtTq",
        "outputId": "8fa2f7a4-642b-494f-b2f5-13f0d6152ad0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------------------+-----+-----+-----+-------+\n",
            "|          Date_Time|      Date|      Cleaned_Tweets|p_neg|p_neu|p_pos| p_comp|\n",
            "+-------------------+----------+--------------------+-----+-----+-----+-------+\n",
            "|2022-01-31 23:59:57|2022-01-31|Bitcoin is one of...|  0.0|0.809|0.191| 0.8555|\n",
            "|2022-01-31 23:59:52|2022-01-31|Lol Oh you just r...|  0.0|0.608|0.392| 0.7003|\n",
            "|2022-01-31 23:59:46|2022-01-31|One of the larges...|0.244|0.659|0.097|-0.5859|\n",
            "|2022-01-31 23:59:33|2022-01-31|However if the re...|  0.0|  1.0|  0.0|    0.0|\n",
            "|2022-01-31 23:59:33|2022-01-31|The CoinShares re...|0.058|0.942|  0.0| -0.296|\n",
            "+-------------------+----------+--------------------+-----+-----+-----+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Truncating timestamps to hours and then grouping them by hour"
      ],
      "metadata": {
        "id": "vfzti0Fdw3YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_truncated = ((round(unix_timestamp(col('Date_Time')) / 3600) * 3600).cast('timestamp'))\n",
        "FinalTw = FinalTw.withColumn('dt_truncated', dt_truncated)\n",
        "FinalTw = FinalTw.selectExpr(\"dt_truncated as Date_Time\",\"Cleaned_Tweets\",\"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "UTC = ((unix_timestamp(col('Date_Time'))+ 5*60*60).cast('timestamp'))\n",
        "FinalTw = FinalTw.withColumn('UTC', UTC)\n",
        "FinalTw = FinalTw.selectExpr(\"UTC as Date_Time\",\"Cleaned_Tweets\",\"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "FinalTw.show(5)"
      ],
      "metadata": {
        "id": "Oxcqrguzw6Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking average of days"
      ],
      "metadata": {
        "id": "THvmVPcf0gZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FinalTw.drop(\"Date_Time\")\n",
        "FinalTw.registerTempTable(\"temp\")\n",
        "FinalTw_avg = sql.sql(\"SELECT Date As DateTime,AVG(p_neg) as P_Neg,AVG(p_neu) as P_Neu,AVG(p_pos) as P_Pos,AVG(p_comp) as P_Comp FROM temp GROUP BY Date\")\n",
        "#FinalTw_avg = FinalTw.select(\"Date_Time\",\"polarity\",\"subj\",\"p_pos\",\"p_neg\").groupBy(\"Date_Time\").agg(avg(col(\"polarity\",\"subj\",\"p_pos\",\"p_neg\")))\n",
        "FinalTw_avg.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrQdphFD0grK",
        "outputId": "c4b90cb4-9ce9-4ac2-9ed0-06ac59028fa2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+-------------------+-------------------+\n",
            "|  DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+\n",
            "|2022-05-17|0.009156249929219484|0.8687187507748604|0.12215624912641943|0.25801249488722533|\n",
            "|2022-03-30| 0.04526760607538089|0.8738309841760448|0.08088732358645385|0.08610422334725588|\n",
            "|2022-01-20| 0.05092105249825277|0.8320789446956233|0.11707894827582334|0.13804473522070207|\n",
            "|2022-07-04|  0.0558899077458666|0.8130733942219971| 0.1310733939529559| 0.2161155941494561|\n",
            "|2022-07-08| 0.02996296242431358|0.8743703718538638|0.09566666765345468|0.23285555018594972|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is just to collect all the corpus per hour(for the future work)"
      ],
      "metadata": {
        "id": "_JEf3Dra05ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import functions as f\n",
        "df_with_text = FinalTw.groupby(\"Date_Time\").agg(f.concat_ws(\" \", f.collect_list(FinalTw.Cleaned_Tweets)))\n",
        "df_with_text.show(1)\n"
      ],
      "metadata": {
        "id": "cELZFTOG05wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting by time"
      ],
      "metadata": {
        "id": "wZ156Atg1Dwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FinalTw_avg.count()\n",
        "from pyspark.sql.functions import *\n",
        "df_sort = FinalTw_avg.sort(asc(\"DateTime\"))\n",
        "df_sort.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKiVc0M1EGV",
        "outputId": "b8075a51-6057-422c-b46d-f55f6fd02d1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+-------------------+-------------------+\n",
            "|  DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+\n",
            "|2022-01-01|  0.0377575760763703|0.8556363636797125|0.10663636356140628|0.18419696785735362|\n",
            "|2022-01-02| 0.05392307702165384|0.8503076938482431|0.09576923084946778|0.08094615374620144|\n",
            "|2022-01-03| 0.07260606234723871|0.8002121204679663|0.12709090813542856|0.10791515299316609|\n",
            "|2022-01-04|0.046699999943375585|0.8399600023031235|0.11336000017821789|0.12076200090348721|\n",
            "|2022-01-05| 0.04544117696145002| 0.839235296144205| 0.1153529422248111| 0.2100970550056766|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading BTC Dataset"
      ],
      "metadata": {
        "id": "iDfN4STSFIwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BtcDF=pd.read_csv('BTC-USD.csv',error_bad_lines=False,engine = 'python',header = None) \n",
        "FullDataBtc=sql.createDataFrame(BtcDF)\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('0', 'DateTime')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('1', 'Open')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('2', 'High')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('3', 'Low')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('4', 'Close')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('5', 'Price')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('6', 'Volume')\n",
        "FullDataBtc=FullDataBtc.filter(FullDataBtc.DateTime!='Date')\n",
        "FullDataBtc=FullDataBtc.drop(\"Open\",\"High\",\"Low\",\"Close\",\"Volume\")\n",
        "FullDataBtc.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uaqLtiQFJHv",
        "outputId": "f45a51b5-604f-4bdc-e40d-49d59895faf6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|  DateTime|       Price|\n",
            "+----------+------------+\n",
            "|2022-01-01|47686.812500|\n",
            "|2022-01-02|47345.218750|\n",
            "|2022-01-03|46458.117188|\n",
            "|2022-01-04|45897.574219|\n",
            "|2022-01-05|43569.003906|\n",
            "+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Nasdaq(Stock) Dataset"
      ],
      "metadata": {
        "id": "1giv1VrLy02E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nasdaqDF=pd.read_csv('nasdaq2022.csv',error_bad_lines=False,engine = 'python',header = None) \n",
        "FullDatanasdaq=sql.createDataFrame(nasdaqDF)\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('0', 'DateTime')\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('1', 'Open')\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('2', 'High')\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('3', 'Low')\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('4', 'Close')\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('5', 'Price')\n",
        "FullDatanasdaq = FullDatanasdaq.withColumnRenamed('6', 'Volume')\n",
        "FullDatanasdaq=FullDatanasdaq.filter(FullDatanasdaq.DateTime!='Date')\n",
        "FullDatanasdaq=FullDatanasdaq.drop(\"Open\",\"High\",\"Low\",\"Close\",\"Volume\")\n",
        "FullDatanasdaq.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fq_LQ8iy1Kb",
        "outputId": "44731d4c-43f7-498c-f17a-90cebdf6a5ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|  DateTime|       Price|\n",
            "+----------+------------+\n",
            "|2022-01-03|15832.799805|\n",
            "|2022-01-04|15622.719727|\n",
            "|2022-01-05|15100.169922|\n",
            "|2022-01-06|15080.860352|\n",
            "|2022-01-07|14935.900391|\n",
            "+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joining twitter and bitcoin dataframes by DateTime"
      ],
      "metadata": {
        "id": "w_2-Yg3RILS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sort.registerTempTable(\"avgs\")\n",
        "FullDataBtc.registerTempTable(\"prices\")\n",
        "FullDatanasdaq.registerTempTable(\"nasdaqprices\")\n",
        "\n",
        "resultsBTC = sql.sql(\"SELECT nasdaqprices.DateTime, P_Neg, P_Neu, P_Pos, P_Comp, prices.Price FROM avgs JOIN prices ON avgs.DateTime = prices.DateTime JOIN nasdaqprices ON nasdaqprices.DateTime = prices.DateTime order by avgs.DateTime\")\n",
        "#results = results.selectExpr(\"DateTime\",\"avg(polarity)\",\"avg(subj)\",\"avg(p_pos)\",\"avg(p_neg)\",\"Price\") Use this line if you are using text blob package\n",
        "resultsBTC.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULWM3H5SIOFG",
        "outputId": "f89e7f06-bf0a-4a24-872a-892256868a34"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+-------------------+-------------------+------------+\n",
            "|  DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|       Price|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+------------+\n",
            "|2022-01-03| 0.07260606234723871|0.8002121204679663|0.12709090813542856|0.10791515299316609|46458.117188|\n",
            "|2022-01-04|0.046699999943375585|0.8399600023031235|0.11336000017821789|0.12076200090348721|45897.574219|\n",
            "|2022-01-05| 0.04544117696145002| 0.839235296144205| 0.1153529422248111| 0.2100970550056766|43569.003906|\n",
            "|2022-01-06|  0.0707727274434133| 0.841568182815205| 0.0875909089280123|0.06692272873426025|43160.929688|\n",
            "|2022-01-07| 0.06091891903732274|0.8430810828466673|0.09600000073378151| 0.0921486464102526|41557.902344|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsNasdaq = sql.sql(\"SELECT avgs.DateTime, P_Neg, P_Neu, P_Pos, P_Comp, nasdaqprices.Price FROM avgs JOIN nasdaqprices ON avgs.DateTime = nasdaqprices.DateTime order by avgs.DateTime\")\n",
        "#results = results.selectExpr(\"DateTime\",\"avg(polarity)\",\"avg(subj)\",\"avg(p_pos)\",\"avg(p_neg)\",\"Price\") Use this line if you are using text blob package\n",
        "resultsNasdaq.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcQwvnR605at",
        "outputId": "73e13d43-83b6-430e-b84b-60d65c602039"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+-------------------+-------------------+------------+\n",
            "|  DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|       Price|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+------------+\n",
            "|2022-01-03| 0.07260606234723871|0.8002121204679663|0.12709090813542856|0.10791515299316609|15832.799805|\n",
            "|2022-01-04|0.046699999943375585|0.8399600023031235|0.11336000017821789|0.12076200090348721|15622.719727|\n",
            "|2022-01-05| 0.04544117696145002| 0.839235296144205| 0.1153529422248111| 0.2100970550056766|15100.169922|\n",
            "|2022-01-06|  0.0707727274434133| 0.841568182815205| 0.0875909089280123|0.06692272873426025|15080.860352|\n",
            "|2022-01-07| 0.06091891903732274|0.8430810828466673|0.09600000073378151| 0.0921486464102526|14935.900391|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsNasdeqBTC = sql.sql(\"SELECT nasdaqprices.DateTime, P_Neg, P_Neu, P_Pos, P_Comp, prices.Price, nasdaqprices.Price as nasdaqPrice FROM avgs JOIN prices ON avgs.DateTime = prices.DateTime JOIN nasdaqprices ON nasdaqprices.DateTime = prices.DateTime order by avgs.DateTime\")\n",
        "#results = results.selectExpr(\"DateTime\",\"avg(polarity)\",\"avg(subj)\",\"avg(p_pos)\",\"avg(p_neg)\",\"Price\") Use this line if you are using text blob package\n",
        "resultsNasdeqBTC.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUvnqT1g_pH7",
        "outputId": "63c3763b-9130-4aa8-8526-451332b18874"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+-------------------+-------------------+------------+------------+\n",
            "|  DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|       Price| nasdaqPrice|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+------------+------------+\n",
            "|2022-01-03| 0.07260606234723871|0.8002121204679663|0.12709090813542856|0.10791515299316609|46458.117188|15832.799805|\n",
            "|2022-01-04|0.046699999943375585|0.8399600023031235|0.11336000017821789|0.12076200090348721|45897.574219|15622.719727|\n",
            "|2022-01-05| 0.04544117696145002| 0.839235296144205| 0.1153529422248111| 0.2100970550056766|43569.003906|15100.169922|\n",
            "|2022-01-06|  0.0707727274434133| 0.841568182815205| 0.0875909089280123|0.06692272873426025|43160.929688|15080.860352|\n",
            "|2022-01-07| 0.06091891903732274|0.8430810828466673|0.09600000073378151| 0.0921486464102526|41557.902344|14935.900391|\n",
            "+----------+--------------------+------------------+-------------------+-------------------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsBTC.write.csv(\"Final-BTC-Tweet.csv\")\n",
        "resultsNasdaq.write.csv(\"Final-Nasdaq-Tweet.csv\")\n",
        "resultsNasdeqBTC.write.csv(\"Final-Nasdaq-btc-Tweet.csv\")"
      ],
      "metadata": {
        "id": "ex4q7XUsMGPp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save csv"
      ],
      "metadata": {
        "id": "57sx3REIJbhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultsBTC.repartition(1).write.csv(\"DataforModelExec.csv\") #this will write df to single csv instead of writing diff csv acc to partitions "
      ],
      "metadata": {
        "id": "O6rIBZOqJb5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}